# -*- coding: utf-8 -*-
import json
import os
from pathlib import Path
from typing import Optional

import numpy as np

from tavi.data.nxdict import spicelogs_to_nested_dict


def read_spice_datafile(file_name: str):
    """Reads an ascii generated by spice, and returns a header structure and a data table

    Args:
        file_name (str): a string containing the filename

    Returns:
        data (np.ndarray): an array containing all columns/rows
        metadata (dict): a dictionary containing information from the commented lines.
        col_names (tuple): name of each collum in spice_data
        others (tuple): unrecogonized lines
        error_messages(tuple): contains line of error message such as unreachable motor positions
    """
    with open(file_name, encoding="utf-8") as f:
        all_content = f.readlines()

    headers = [line.strip() for line in all_content if "#" in line]
    index_col_name = headers.index("# col_headers =")
    col_names = headers[index_col_name + 1].strip("#").split()
    # remove the dot before it causes problem
    # index_of_pt = col_names.index("Pt.")
    # col_names[index_of_pt] = "Pt"
    metadata_list = headers[:index_col_name]
    error_messages = headers[index_col_name + 2 :]

    index_sum_count = [i for i, header in enumerate(headers) if header.startswith("# Sum of Counts =")]
    # in case "Sum of Counts" doesn't exist
    # happens to the last scan after beam is down
    if len(index_sum_count) != 0:
        metadata_list += headers[index_sum_count[0] :]
        error_messages = error_messages[: index_sum_count[0] - len(headers)]

    metadata = {}
    others = []

    for metadata_entry in metadata_list:
        line = metadata_entry.strip("# ")

        if "completed" in line or "stopped" in line:  # last line
            parts = line.split(" ")
            end_time = parts[3] + " " + parts[0] + " " + parts[1]
            metadata.update({"end_time": end_time})
        # elif line[-1] == "=":  # empty line
        #     unused.append(line[:-2])  # remove  " ="
        elif "=" in line:  # useful line
            parts = line.split("=")
            key = parts[0].strip()
            val = "=".join(parts[1:])[1:]  # remove the fisrt space charactor
            metadata.update({key: val})
        else:  # how did you get here?
            others.append(line)
    # others = tuple(others)

    data = np.genfromtxt(file_name, comments="#")

    return (data, tuple(col_names), metadata, tuple(others), tuple(error_messages))


def read_spice_ubconf(ub_file_name: str):
    """Reads ub info from UBConf"""
    ubconf = {}
    with open(ub_file_name, encoding="utf-8") as f:
        all_content = f.readlines()

    for idx, line in enumerate(all_content):
        if line.strip() == "":
            continue  # skip if empty
        elif line.strip()[0] == "[":
            continue  # skiplines like "[xx]"

        key, val = line.strip().split("=")
        if key == "Mode":
            mode_name = all_content[idx - 1].strip()
            if mode_name == "[UBMode]":
                ubconf.update({"UBMode": int(val)})
            elif mode_name == "[AngleMode]":
                ubconf.update({"AngleMode": int(val)})
        elif "," in line:  # vector
            ubconf.update({key: np.array([float(v) for v in val.strip('"').split(",")])})
        else:  # float number
            ubconf.update({key: float(val)})

    return ubconf


def format_spice_header(headers):
    """Convert metadata in SPICE to be appropriate format."""

    formatted_headers = {}

    exp_str = ["scan_title", "users", "local_contact", "experiment"]
    for k, v in headers.items():
        if "," in v and k not in exp_str:  # vectors
            vec = np.array([float(v0) for v0 in v.split(",")])
            formatted_headers.update({k: vec})
        elif v.replace(".", "").isnumeric():  # numebrs only
            if v.isdigit():  # int
                formatted_headers.update({k: int(v)})
            else:  # float
                formatted_headers.update({k: float(v)})
        # separate COM/FWHM and its errorbar
        elif k == "Center of Mass":
            if v == "NaN+/-NaN":
                formatted_headers.update({"COM": np.nan, "COM_err": np.nan})
            else:
                com, e_com = v.split("+/-")
                formatted_headers.update({"COM": float(com), "COM_err": float(e_com)})
        elif k == "Full Width Half-Maximum":
            if v == "NaN+/-NaN":
                formatted_headers.update({"FWHM": np.nan, "FWHM_err": np.nan})
            else:
                fwhm, e_fwhm = v.split("+/-")
                formatted_headers.update({"FWHM": float(fwhm), "FWHM_err": float(e_fwhm)})
        else:  # other crap, keep as is
            formatted_headers.update({k: v})

    return formatted_headers


def _create_spicelogs(path_to_scan_file: str) -> dict:
    """read in SPICE data, return a dictionary containing metadata and data columns"""
    (data, col_names, metadata, others, error_messages) = read_spice_datafile(path_to_scan_file)

    # write SPICElogs attributes
    attrs_dict = {"NX_class": "NXcollection", "EX_required": "false"}
    for k, v in metadata.items():
        attrs_dict.update({k: v})
    if len(error_messages) != 0:
        attrs_dict.update({"Error Messages": error_messages})
    if len(others) != 0:
        attrs_dict.update({"Others": others})

    # write SPICElogs datasets
    dataset_dict = {}
    spice_data_shape = data.shape
    if len(spice_data_shape) == 1:  # 1 row ony
        if spice_data_shape[0] != 0:
            for idx, col_header in enumerate(col_names):
                dataset_dict.update({col_header: data[idx]})
        else:  # ignore if empty
            pass
    elif len(spice_data_shape) == 2:  # nomarl data with mutiple rows
        # print(scan_num)
        # print(spice_data.shape)
        for idx, col_header in enumerate(col_names):
            dataset_dict.update({col_header: data[:, idx]})
    spicelogs = {"metadata": attrs_dict}
    spicelogs.update(dataset_dict)
    return spicelogs


def spice_scan_to_nxdict(
    path_to_scan_file: str,
    path_to_instrument_json: Optional[str] = None,
    path_to_sample_json: Optional[str] = None,
) -> dict:
    """Format SPICE data in a nested dictionary format"""

    # parse instruemnt and sample json files
    instrument_config_params = None
    if path_to_instrument_json is not None:
        instrument_config = Path(path_to_instrument_json)
        if not instrument_config.is_file():
            raise ValueError(f"Invalid instrument json file path: {path_to_instrument_json}")
        with open(instrument_config, "r", encoding="utf-8") as file:
            instrument_config_params = json.load(file)

    sample_config_params = None
    if path_to_sample_json is not None:
        sample_config = Path(path_to_sample_json)
        if not sample_config.is_file():
            raise ValueError(f"Invalid sample json file path: {path_to_instrument_json}")
        with open(sample_config, "r", encoding="utf-8") as file:
            sample_config_params = json.load(file)

    spicelogs = _create_spicelogs(path_to_scan_file)

    nxdict = spicelogs_to_nested_dict(
        spicelogs,
        instrument_dict=instrument_config_params,
        sample_dict=sample_config_params,
    )
    return nxdict


def spice_data_to_nxdict(
    path_to_spice_folder: str,
    scan_num: Optional[int] = None,
    path_to_instrument_json: Optional[str] = None,
    path_to_sample_json: Optional[str] = None,
) -> dict:
    """Read SPICE data files into nested dictionary, ready to be converted to NeXus format

    Args:
           path_to_spice_folder (str): path to a SPICE folder
           scan_num (int): read all scans in folder if not None, otherwise read one scan only
           path_to_instrument_json: Optional[str] = None,
           path_to_sample_json: Optional[str] = None,
    """
    if path_to_spice_folder[-1] != "/":
        path_to_spice_folder += "/"

    scan_list = os.listdir(path_to_spice_folder + "Datafiles/")
    if scan_num is None:  # read all scans in folder
        filter_keyword = ".dat"
    else:  # read one scan only
        filter_keyword = f"scan{scan_num:04}.dat"

    scan_list = [path_to_spice_folder + "Datafiles/" + scan for scan in scan_list if scan.endswith(filter_keyword)]
    scan_list.sort()

    # get IPTS number and instrument string
    first_scan = scan_list[0]
    (_, _, headers, _, _) = read_spice_datafile(first_scan)
    ipts = headers["proposal"]
    spice_file_name = first_scan.split("/")[-1]  # e.g. CG4C_exp0424_scan0001.dat
    instrument_str, exp_num, _ = spice_file_name.split("_")
    dataset_name = f"IPTS{ipts}_{instrument_str}_{exp_num}"

    nexus_dict = {}
    for path_to_scan_file in scan_list:
        pass

        scan_name, scan_dict = spice_scan_to_nxdict(
            path_to_scan_file,
            path_to_instrument_json,
            path_to_sample_json,
        )

        nexus_dict.update({scan_name: scan_dict})
        nexus_dict[scan_name]["attrs"].update({"dataset_name": dataset_name})

    return nexus_dict
