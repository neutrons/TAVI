# -*- coding: utf-8 -*-
import os
import xml.etree.ElementTree as ET
from typing import Any

import numpy as np


def read_spice_datafile(file_name: str):
    """Reads an ascii generated by spice, and returns a header structure and a data table

    Args:
        file_name (str): a string containing the filename

    Returns:
        data (np.ndarray): an array containing all columns/rows
        metadata (dict): a dictionary containing information from the commented lines.
        col_names (tuple): name of each column in spice_data
        others (tuple): unrecogonized lines
        error_messages(tuple): contains line of error message such as unreachable motor positions
    """
    with open(file_name, encoding="utf-8") as f:
        all_content = f.readlines()

    headers = [line.strip() for line in all_content if "#" in line]
    index_col_name = headers.index("# col_headers =")
    col_names = headers[index_col_name + 1].strip("#").split()
    # remove the dot before it causes problem
    # index_of_pt = col_names.index("Pt.")
    # col_names[index_of_pt] = "Pt"
    metadata_list = headers[:index_col_name]
    error_messages = headers[index_col_name + 2 :]

    index_sum_count = [i for i, header in enumerate(headers) if header.startswith("# Sum of Counts =")]
    # in case "Sum of Counts" doesn't exist
    # happens to the last scan after beam is down
    if len(index_sum_count) != 0:
        metadata_list += headers[index_sum_count[0] :]
        error_messages = error_messages[: index_sum_count[0] - len(headers)]

    metadata = {}
    others = []

    for metadata_entry in metadata_list:
        line = metadata_entry.strip("# ")

        if "completed" in line or "stopped" in line:  # last line
            parts = line.split(" ")
            end_time = parts[3] + " " + parts[0] + " " + parts[1]
            metadata.update({"end_time": end_time})
        # elif line[-1] == "=":  # empty line
        #     unused.append(line[:-2])  # remove  " ="
        elif "=" in line:  # useful line
            parts = line.split("=")
            key = parts[0].strip()
            val = "=".join(parts[1:])[1:]  # remove the fisrt space character
            metadata.update({key: val})
        else:  # how did you get here?
            others.append(line)
    # others = tuple(others)

    if metadata.get("preset_type") == "countfile":  # HB1 in polarization mode
        countfile = []
        norm_vals = []
        norm_channels = []
        labels = []
        label_p = ""
        label_sf = ""
        num = 1
        for metadata_entry in metadata_list:
            if metadata_entry.startswith("# countfile"):
                _, val = metadata_entry.split("=")
                # determin the directio of polarization
                if "parq" in val:
                    label_p = "Px"
                elif "perpqh" in val:
                    label_p = "Py"
                elif "perpq" in val:
                    label_p = "Pz"
                # detemine SF or NSF
                if ("drive hguide off vguide off" in val) or ("floff" in val) or ("drive hguide 0 vguide 0" in val):
                    label_sf = "NSF"
                elif ("drive hguide on vguide on" in val) or ("flon" in val) or ("drive" in val):
                    label_sf = "SF"
                if "count preset" in val:
                    (*_, norm_channel, norm_val) = val.split()
                    norm_vals.append(float(norm_val))
                    norm_channels.append(norm_channel + f"_{num}")
                    labels.append(" ".join([label_p, label_sf]))
                    num += 1

                countfile.append(val.strip())
        metadata.update({"countfile": ", ".join(countfile)})
        metadata.update({"norm_vals": norm_vals})
        metadata.update({"norm_channels": norm_channels})
        metadata.update({"labels": labels})

    data = np.genfromtxt(file_name, comments="#")

    return (data, tuple(col_names), metadata, tuple(others), tuple(error_messages))


def read_spice_ubconf(ub_file_name: str) -> dict:
    """Reads ub info from UBConf
    Args:
        ub_file_name (str): a string containing the filename

    Returns:
    """
    ubconf: dict[str, Any] = {}
    with open(ub_file_name, "r", encoding="utf-8") as f:
        all_content = f.readlines()

    if all_content[0] == "[UBMode]\n":
        for idx, line in enumerate(all_content):
            if line.strip() == "":
                continue  # skip if empty
            elif line.strip()[0] == "[":
                continue  # skiplines like "[xx]"
            key, val = line.strip().split("=")

            if key == "Mode":
                mode_name = all_content[idx - 1].strip()
                if mode_name == "[UBMode]":
                    ubconf.update({"UBMode": int(val)})
                elif mode_name == "[AngleMode]":
                    ubconf.update({"AngleMode": int(val)})
            elif "," in val:  # string of vector to array
                ubconf.update({key: np.array([float(v) for v in val.strip('"').split(",")])})
            elif val == '""':  # no value
                pass
            else:  # float
                ubconf.update({key: float(val)})
    else:  # xml junk from C#
        tree = ET.parse(ub_file_name)
        root = tree.getroot()
        for matrix in root.findall("matrix"):
            ub_matrix = matrix.attrib["matrix"].split(" ")
        ub_matrix = [s for s in ub_matrix if s]  # filter
        ubconf.update({"UBMatrix": np.array([float(ub_matrix[i]) for i in range(9)])})
    return ubconf


def _create_spicelogs(path_to_scan_file: str) -> dict:
    """read in SPICE data, return a dictionary containing metadata and data columns"""

    (data, col_names, metadata, others, error_messages) = read_spice_datafile(path_to_scan_file)
    *_, file_name = path_to_scan_file.split("/")
    instrument_str, *_ = file_name.split("_")
    # write SPICElogs attributes
    attrs_dict = {"instrument": instrument_str}
    for k, v in metadata.items():
        attrs_dict.update({k: v})
    if len(error_messages) != 0:
        attrs_dict.update({"Error Messages": error_messages})
    if len(others) != 0:
        attrs_dict.update({"Others": others})

    # write SPICElogs datasets
    dataset_dict = {}
    spice_data_shape = data.shape
    if len(spice_data_shape) == 1:  # 1 row only
        if spice_data_shape[0] != 0:
            for idx, col_header in enumerate(col_names):
                # convert to ndarray if one point only
                dataset_dict.update({col_header: np.array([data[idx]])})
        else:  # ignore if empty
            pass
    elif len(spice_data_shape) == 2:  # nomarl data with multiple rows
        # print(scan_num)
        # print(spice_data.shape)
        for idx, col_header in enumerate(col_names):
            dataset_dict.update({col_header: data[:, idx]})
    spicelogs = {"metadata": attrs_dict}
    spicelogs.update(dataset_dict)

    scan_path = os.path.abspath(path_to_scan_file)
    folder_path = os.path.dirname(os.path.split(scan_path)[0])

    ub_file_name = metadata["ubconf"]
    # clean up the mess DAC made
    if "\\" in ub_file_name:  # ubconf can be a Windows path in some scans
        ub_file = ub_file_name.split("\\")[-1]
    elif "/" in ub_file_name:  # ubconf can be a Windows path in some scans
        ub_file = ub_file_name.split("/")[-1]
    else:
        ub_file = ub_file_name

    ub_file_path = os.path.join("/", folder_path, "UBConf", ub_file)
    ub_temp_file_path = os.path.join("/", folder_path, "UBConf", "temp", ub_file)

    if os.path.isfile(ub_file_path):
        ub_conf_dict = {"file_path": ub_file_path}
    elif os.path.isfile(ub_temp_file_path):
        ub_conf_dict = {"file_path": ub_temp_file_path}
    else:
        # ub_conf_dict = {"file_path": ""}
        ub_conf_dict = {}
        print(f"Cannot find UB file {metadata['ubconf']}")

    if not ub_conf_dict:
        pass
    else:
        ubconf = read_spice_ubconf(ub_file_path)
        for k, v in ubconf.items():
            ub_conf_dict.update({k: v})

        spicelogs.update({"ub_conf": ub_conf_dict})

    return spicelogs
