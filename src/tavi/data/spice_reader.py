# -*- coding: utf-8 -*-
import json
import os
from pathlib import Path
from typing import Optional

import numpy as np

from tavi.data.nxdict import daslogs_to_nexus_dict


def read_spice_datafile(file_name: str):
    """Reads an ascii generated by spice, and returns a header structure and a data table

    Args:
        file_name (str): a string containing the filename

    Returns:
        spice_data (np.ndarray): an array containing all columns/rows
        headers (dict): a dictionary containing information from the commented lines.
        col_headers (tuple): name of each collum in spice_data
        others (tuple): unrecogonized variables
    """
    with open(file_name, encoding="utf-8") as f:
        all_content = f.readlines()

    metadata = [line.strip() for line in all_content if "#" in line]
    index_col_name = metadata.index("# col_headers =")
    col_headers = metadata[index_col_name + 1].strip("#").split()
    col_headers[0] = "Pt"  # remove the dot
    col_headers = tuple(col_headers)
    metadata_list = metadata[:index_col_name]
    error_messages = metadata[index_col_name + 2 :]

    index_sum_count = [i for i, header in enumerate(metadata) if header.startswith("# Sum of Counts =")]
    # in case "Sum of Counts" doesn't exist
    # happens to the last scan after beam is down
    if len(index_sum_count) != 0:
        metadata_list += metadata[index_sum_count[0] :]
        error_messages = tuple(error_messages[: index_sum_count[0] - len(metadata)])

    headers = {}
    others = ()

    for metadata_entry in metadata_list:
        line = metadata_entry.strip("# ")

        if "completed" in line or "stopped" in line:  # last line
            parts = line.split(" ")
            headers["end_time"] = parts[3] + " " + parts[0] + " " + parts[1]
        # elif line[-1] == "=":  # empty line
        #     unused.append(line[:-2])  # remove  " ="
        elif "=" in line:  # useful line
            parts = line.split("=")
            key = parts[0].strip()
            val = "=".join(parts[1:])[1:]  # remove the fisrt space charactor
            headers[key] = val
        else:  # how did you get here?
            others += (line,)
    # others = tuple(others)

    spice_data = np.genfromtxt(file_name, comments="#")

    return (spice_data, col_headers, headers, others, error_messages)


def read_spice_ubconf(ub_file_name: str):
    """Reads ub info from UBConf"""
    ubconf = {}
    with open(ub_file_name, encoding="utf-8") as f:
        all_content = f.readlines()

    for idx, line in enumerate(all_content):
        if line.strip() == "":
            continue  # skip if empty
        elif line.strip()[0] == "[":
            continue  # skiplines like "[xx]"

        ub_dict = {}
        key, val = line.strip().split("=")
        if key == "Mode":
            if all_content[idx - 1].strip() == "[UBMode]":
                ub_dict["UBMode"] = int(val)
            elif all_content[idx - 1].strip() == "[AngleMode]":
                ub_dict["AngleMode"] = int(val)
        else:
            if "," in line:  # vector
                ub_dict[key] = np.array([float(v) for v in val.strip('"').split(",")])
            else:  # float number
                ub_dict[key] = float(val)

        ubconf.update(ub_dict)

    return ubconf


def format_spice_header(headers):
    """Convert metadata in SPICE to be approperiate format"""

    formatted_headers = {}

    exp_str = ["scan_title", "users", "local_contact", "experiment"]
    for k, v in headers.items():
        if "," in v and k not in exp_str:  # vectors
            vec = np.array([float(v0) for v0 in v.split(",")])
            formatted_headers.update({k: vec})
        elif v.replace(".", "").isnumeric():  # numebrs only
            if v.isdigit():  # int
                formatted_headers.update({k: int(v)})
            else:  # float
                formatted_headers.update({k: float(v)})
        # separate COM/FWHM and its errorbar
        elif k == "Center of Mass":
            if v == "NaN+/-NaN":
                formatted_headers.update({"COM": np.nan, "COM_err": np.nan})
            else:
                com, e_com = v.split("+/-")
                formatted_headers.update({"COM": float(com), "COM_err": float(e_com)})
        elif k == "Full Width Half-Maximum":
            if v == "NaN+/-NaN":
                formatted_headers.update({"FWHM": np.nan, "FWHM_err": np.nan})
            else:
                fwhm, e_fwhm = v.split("+/-")
                formatted_headers.update({"FWHM": float(com), "FWHM_err": float(e_com)})
        else:  # other crap, keep as is
            formatted_headers.update({k: v})

    return formatted_headers


def create_spicelogs(path_to_scan_file: str) -> tuple[str, dict]:
    """read in SPICE data, return a dictionary"""
    (
        spice_data,
        col_headers,
        headers,
        others,
        error_messages,
    ) = read_spice_datafile(path_to_scan_file)
    formatted_headers = format_spice_header(headers)

    ipts = headers["proposal"]
    spice_file_name = path_to_scan_file.split("/")[-1]  # e.g. CG4C_exp0424_scan0001.dat
    instrument_str, exp_num, scan_num = spice_file_name.split("_")
    scan_name = scan_num.split(".")[0]  # e.g. "scan0001"

    attrs_dict = {
        "NX_class": "NXcollection",
        "EX_required": "false",
        "instrument": instrument_str,
    }
    # write SPICElogs attributes
    for k, v in formatted_headers.items():
        attrs_dict.update({k: v})
    if len(error_messages) != 0:
        attrs_dict.update({"Error Messages": error_messages})

    dataset_dict = {}
    # write SPICElogs datasets
    spice_data_shape = spice_data.shape
    if len(spice_data_shape) == 1:  # 1 row ony
        if spice_data_shape[0] != 0:
            for idx, col_header in enumerate(col_headers):
                dataset_dict.update({col_header: spice_data[idx]})
        else:  # ignore if empty
            pass
    elif len(spice_data_shape) == 2:  # nomarl data with mutiple rows
        # print(scan_num)
        # print(spice_data.shape)
        for idx, col_header in enumerate(col_headers):
            dataset_dict.update({col_header: spice_data[:, idx]})
    spicelogs = {"SPICElogs": {"attrs": attrs_dict}}
    spicelogs["SPICElogs"].update(dataset_dict)
    # spicelogs = {"SPICElogs": {"attrs": attrs_dict, "dataset": dataset_dict}}
    return scan_name, spicelogs


def convert_spice_data_to_nexus_dict(
    path_to_scan_file: str,
    path_to_instrument_json: Optional[str],
    path_to_sample_json: Optional[str],
) -> tuple[str, dict]:
    """Format SPICE data in a nested dictionary format"""

    # parse instruemnt and sample json files
    instrument_config_params = None
    if path_to_instrument_json is not None:
        instrument_config = Path(path_to_instrument_json)
        if instrument_config.is_file():
            with open(instrument_config, "r", encoding="utf-8") as file:
                instrument_config_params = json.load(file)

    sample_config_params = None
    if path_to_sample_json is not None:
        sample_config = Path(path_to_sample_json)
        if sample_config.is_file():
            with open(sample_config, "r", encoding="utf-8") as file:
                sample_config_params = json.load(file)

    scan_name, spicelogs = create_spicelogs(path_to_scan_file)

    # Format SPICElogs to NeXus
    scan_dict = daslogs_to_nexus_dict(
        spicelogs,
        instrument_config_params=instrument_config_params,
        sample_config_params=sample_config_params,
    )

    return (scan_name, scan_dict)


def spice_data_reader(
    path_to_spice_folder: str,
    scan_num: Optional[int] = None,
    path_to_instrument_json: Optional[str] = None,
    path_to_sample_json: Optional[str] = None,
) -> dict:
    """Read SPICE data files into nested dictionary, ready to be converted to NeXus format

    Args:
           path_to_spice_folder (str): path to a SPICE folder
           scan_num (int): read all scans in folder if not None
           path_to_instrument_json: Optional[str] = None,
           path_to_sample_json: Optional[str] = None,
    """
    if path_to_spice_folder[-1] != "/":
        path_to_spice_folder += "/"

    scan_list = os.listdir(path_to_spice_folder + "Datafiles/")
    if scan_num is None:  # read all scans in folder
        filter_keyword = ".dat"
    else:  # read one scan only
        filter_keyword = f"scan{scan_num:04}.dat"
    scan_list = [path_to_spice_folder + "Datafiles/" + scan for scan in scan_list if scan.endswith(filter_keyword)]
    scan_list.sort()

    # get IPTS number and instrument string
    first_scan = scan_list[0]
    (_, _, headers, _, _) = read_spice_datafile(first_scan)
    ipts = headers["proposal"]
    spice_file_name = first_scan.split("/")[-1]  # e.g. CG4C_exp0424_scan0001.dat
    instrument_str, exp_num, _ = spice_file_name.split("_")
    dataset_name = f"IPTS{ipts}_{instrument_str}_{exp_num}"

    nexus_dict = {}
    for path_to_scan_file in scan_list:
        scan_name, scan_dict = convert_spice_data_to_nexus_dict(
            path_to_scan_file,
            path_to_instrument_json,
            path_to_sample_json,
        )
        nexus_dict.update({scan_name: scan_dict})
        nexus_dict[scan_name]["attrs"].update({"dataset_name": dataset_name})

    return nexus_dict
